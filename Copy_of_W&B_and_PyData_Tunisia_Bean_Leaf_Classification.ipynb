{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of W&B and PyData Tunisia - Bean Leaf Classification",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anas4444/HackathonDevWebGroupe10/blob/main/Copy_of_W%26B_and_PyData_Tunisia_Bean_Leaf_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn2AsN_8OF9C"
      },
      "source": [
        "<img src=\"https://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "<!--- @wandbcode{beans-comp-pydata-tunisia} -->\n",
        "\n",
        "Use Weights & Biases for machine learning experiment tracking, dataset versioning, and project collaboration.\n",
        "\n",
        "\n",
        "<img src=\"https://wandb.me/mini-diagram\" width=\"650\" alt=\"Weights & Biases\" />\n",
        "\n",
        "\n",
        "## What this notebook covers with Weights and Biases:\n",
        "* Metrics logging \n",
        "* Exploratory Data Analysis (EDA)\n",
        "* W&B plots such as Confusion Matrices, ROC curves & PR curves\n",
        "* HyperParameter search with W&B Sweeps\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNu4MLLEWoGm"
      },
      "source": [
        "# ‚úÖ Sign Up\n",
        "\n",
        "Sign up to a free [Weights & Biases account here](https://wandb.ai/signup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_vAHpRh9hi2"
      },
      "source": [
        "# Kaggle Competition Page\n",
        "\n",
        "[Submit to the Competition here](https://www.kaggle.com/c/bean-comp-pytunisia/overview)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFmx5yiSHodB"
      },
      "source": [
        "# üöÄ Installing and importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32x5NdqZE2e1"
      },
      "source": [
        "!pip install -q --upgrade wandb\n",
        "!pip install -q scikit-learn==1.0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQV_RY7nauWI"
      },
      "source": [
        "import os\n",
        "import wandb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19z3oXf7t6Ng"
      },
      "source": [
        "A useful logging function to log multiple metrics to W&B at once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwReo5oqkqbh"
      },
      "source": [
        "def log_metrics(labels, preds, is_val=True):\n",
        "  if is_val: pref = 'validation'\n",
        "  else: pref = 'train'\n",
        "  \n",
        "  metrics = {}\n",
        "  metrics[f\"{pref}/accuracy_score\"] = accuracy_score(y_val, y_pred)\n",
        "  metrics[f\"{pref}/precision\"] = precision_score(y_val, y_pred, average=\"weighted\")\n",
        "  metrics[f\"{pref}/recall\"] = recall_score(y_val, y_pred, average=\"weighted\")\n",
        "  metrics[f\"{pref}/f1_score\"] = f1_score(y_val, y_pred, average=\"weighted\")\n",
        "\n",
        "  for k in metrics.keys():\n",
        "    print(f'{k} : {metrics[k]}')\n",
        "    wandb.summary[f\"{k}\"] = metrics[k]\n",
        "\n",
        "  #wandb.log(metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK-8urUht2VY"
      },
      "source": [
        "Set some constants "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECCOZJy_Lx5O"
      },
      "source": [
        "PROJECT = 'beans-tabular-pydata-tunisia'\n",
        "DATA_DIR = 'data'\n",
        "ARTIFACT_PATH = 'wandb_fc/beans-tabular-pydata-tunisia/beans_competition_dataset:latest'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHlJ_rz_Izr7"
      },
      "source": [
        "# üíæ Data\n",
        "#### Download and Load the Data\n",
        "`train.csv` and `val.csv` data will be downloaded to `DATA_DIR`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxu2Zl3wHpcU"
      },
      "source": [
        "wandb.init(project=PROJECT, job_type='download_dataset')\n",
        "artifact = wandb.use_artifact(ARTIFACT_PATH, type='dataset')\n",
        "artifact_dir = artifact.download(DATA_DIR)\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baxhbeeeJOM1"
      },
      "source": [
        "# Read csvs to DataFrame\n",
        "train_df = pd.read_csv(f'{DATA_DIR}/train_c.csv')\n",
        "train_df = train_df.sample(frac=1)  # shuffle the train data\n",
        "train_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "val_df = pd.read_csv(f'{DATA_DIR}/val.csv')\n",
        "test_df = pd.read_csv(f'{DATA_DIR}/test_no_label.csv')\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RrvVCnw53JU"
      },
      "source": [
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QatMlpq6VUCD"
      },
      "source": [
        "#### Prep Data\n",
        "Extract the X,y values and encode the classes into integer values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg-B02o5VzBG"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "y_train_txt = train_df['Class'].values.tolist()\n",
        "le.fit(y_train_txt)\n",
        "labels = le.classes_\n",
        "\n",
        "X_train = train_df.iloc[:,:-2].values.tolist()\n",
        "y_train = le.transform(y_train_txt)\n",
        "\n",
        "X_val = val_df.iloc[:,:-2].values.tolist()\n",
        "y_val_txt = val_df['Class'].values.tolist()\n",
        "y_val = le.transform(y_val_txt)\n",
        "\n",
        "X_test = test_df.iloc[:,:-1].values.tolist()\n",
        "\n",
        "labels = train_df['Class'].unique()\n",
        "\n",
        "list(le.inverse_transform([2, 2, 1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZfOpabjL4kf"
      },
      "source": [
        "# üñºÔ∏è EDA with W&B Tables\n",
        "Log the train and validation datasets to W&B Tables for EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD_7X40vHpQ0"
      },
      "source": [
        "wandb.init(project=PROJECT, job_type='log_dataset')\n",
        "wandb.log({'Datasets/train_ds':train_df})\n",
        "wandb.log({'Datasets/val_ds':val_df})\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5ni9t9sfArq"
      },
      "source": [
        "#üëü Train\n",
        "Train a [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) from sci-kit learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2OZsuwfkVMv"
      },
      "source": [
        "wandb.init(project=PROJECT)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# ‚úçÔ∏è Log your Models parameter config to W&B\n",
        "wandb.config.update(model.get_params())\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred = model.predict(X_val)\n",
        "y_probas = model.predict_proba(X_val)\n",
        "\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckURDaqhrhui"
      },
      "source": [
        "‚úçÔ∏è Log your model's Metrics to W&B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b7099kdmHmp"
      },
      "source": [
        "log_metrics(y_val, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9FEchN-sXsn"
      },
      "source": [
        "#ü§© Visualize Model Performance in W&B\n",
        "Weights & Biases have charting functions for popular model evaluation charts including confusion matrices, ROC curves, PR curves and more.\n",
        "[Check out wandb charts documentation here $\\rightarrow$](https://docs.wandb.ai/guides/track/log/plots#model-evaluation-charts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7wQwS8voSB3"
      },
      "source": [
        "**Confusion Matrix**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0T95FIJmQXM"
      },
      "source": [
        "wandb.log({\"confusion Matrix\" : wandb.plot.confusion_matrix(y_probas, y_val, class_names=labels)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATGYTRKnnQBD"
      },
      "source": [
        "**ROC Curve**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO8_V_AanPq9"
      },
      "source": [
        "wandb.log({\"ROC Curve\": wandb.plot.roc_curve(y_val, y_probas, labels=labels, title='ROC Curve')})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZq5a6RpoapA"
      },
      "source": [
        "**Precision Recall Curve**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31ZEnsbRocJl"
      },
      "source": [
        "wandb.log({\"Precision-Recall\": wandb.plot.pr_curve(y_val, y_probas, labels=labels, title='Precision-Recall')})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV66Jrrdolhz"
      },
      "source": [
        "**Feature Importances**\n",
        "\n",
        "Evaluates and plots the importance of each feature for the classification task. Only works with classifiers that have a `feature_importances_` attribute, like trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv-ED9j_qCZA"
      },
      "source": [
        "feat_names = train_df.columns.values\n",
        "imps = []\n",
        "feats = []\n",
        "for i in indices:\n",
        "  imps.append(importances[i])\n",
        "  feats.append(feat_names[i])\n",
        "\n",
        "fi_data = pd.DataFrame({\"Feature\":feats, \"Importance\":imps})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEdaNt9tpqTO"
      },
      "source": [
        "table = wandb.Table(data=fi_data, columns = [\"Feature\", \"Importance\"])\n",
        "wandb.log({\"Feature Importance\" : wandb.plot.bar(table, \"Feature\",\n",
        "                               \"Importance\", title=\"Feature Importance\")})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqO3vXwAuXUT"
      },
      "source": [
        "#### üèÅ Finish W&B Run\n",
        "When you're finished with your logging for a run make sure to call `wandb.finish()` to avoid logging metrics from your next experiment to the wrong run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIHtZ-QEuVV8"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DesBwID32HJ"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZq_oR8f30yY"
      },
      "source": [
        "y_pred_test = model.predict(X_test)\n",
        "y_pred_test = list(le.inverse_transform(y_pred_test))\n",
        "ids = test_df.id.values\n",
        "\n",
        "submission_df = pd.DataFrame({'Id':ids, 'Predicted':y_pred_test})\n",
        "submission_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvVBjQTbpFhV"
      },
      "source": [
        "# üß™ HyperParameter Sweep\n",
        "\n",
        "Weights and Biases also enables you to do hyperparameter sweeps, either with our own [Sweeps functionality](https://docs.wandb.ai/guides/sweeps/python-api)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ixD36XLozvk"
      },
      "source": [
        "#### Sweep Train Function\n",
        "A W&B Sweep needs to passed in a config and a training function to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6TwD4gSsrwo"
      },
      "source": [
        "def train():     \n",
        "    with wandb.init() as _:\n",
        "      \n",
        "      model = RandomForestClassifier(\n",
        "          n_estimators=wandb.config['n_estimators'],   # n_estimators parameter will now be set by W&B\n",
        "          max_depth=wandb.config['max_depth']     # max_depth parameter will now be set by W&B\n",
        "          \n",
        "          # [Optional] add additional model parameters here\n",
        "          \n",
        "          )\n",
        "      \n",
        "      # ‚úçÔ∏è Log your Models parameter config to W&B\n",
        "      wandb.config['model_type'] = 'random_forest'\n",
        "      wandb.config.update(model.get_params())\n",
        "\n",
        "      model.fit(X_train, y_train)\n",
        "\n",
        "      y_pred_train = model.predict(X_train)\n",
        "      y_pred = model.predict(X_val)\n",
        "      y_probas = model.predict_proba(X_val)\n",
        "        \n",
        "      wandb.summary[\"validation/accuracy\"] = accuracy_score(y_val, y_pred)\n",
        "      wandb.summary[\"validation/precision\"] = precision_score(y_val, y_pred, average=\"weighted\")\n",
        "      wandb.summary[\"validation/recall\"] = recall_score(y_val, y_pred, average=\"weighted\")\n",
        "      wandb.summary[\"validation/f1_score\"] = f1_score(y_val, y_pred, average=\"weighted\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHaoTUwkqxNl"
      },
      "source": [
        "üí° **Tip**\n",
        "\n",
        "The `train` function above uses Sci-Kit Learn's [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) but you can also modify the code to user other models such as `DecisionTreeClassifier` or `AdaBoostClassifier` or other boosting models such as [`XGBoost`](https://xgboost.readthedocs.io/en/latest/get_started.html). \n",
        "\n",
        "Note that you'll likely have to chanage the argument names in the `sweep_config` when using these models in a sweep.\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model = AdaBoostClassifier()\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "#### Sweep Config\n",
        "Define the name of your sweep, how you'd like to sweep and what parameters to sweep over. See the [Sweep Configuration Docs](https://docs.wandb.ai/guides/sweeps/configuration) here for more advanced functionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmPoRCjOsrzQ"
      },
      "source": [
        "sweep_config = {\n",
        "  \"name\" : \"beans_sweep\",\n",
        "  \"method\" : \"random\",\n",
        "  \"parameters\" : {\n",
        "    \"n_estimators\" :{\n",
        "      \"min\": 10,\n",
        "      \"max\": 400\n",
        "    },\n",
        "    \"max_depth\" :{\n",
        "      \"min\": 2,\n",
        "      \"max\": 100\n",
        "    },\n",
        "\n",
        "    # [Optional] add additional parameters here\n",
        "\n",
        "  }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=PROJECT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlWEExyQosPw"
      },
      "source": [
        "üí° **Tip**\n",
        "\n",
        "The above `sweeps_config` is very simple, consider sweeping over additional parameters - don't forget to modify your `train` function to pass these additional parameters to your model\n",
        "\n",
        "####¬†Run Sweep\n",
        "Now we define the number of experiments we'd like to run using `N_RUNS`, pass the sweep_id and the training function and then start the sweep\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvEEKlALsrsN"
      },
      "source": [
        "N_RUNS = 50 # number of runs to execute\n",
        "wandb.agent(sweep_id, project=PROJECT, function=train, count=N_RUNS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A4CVu1L1zN0"
      },
      "source": [
        "# ü™Ñ More from W&B\n",
        "#### üé® Example Gallery\n",
        "\n",
        "See examples of projects tracked and visualized with W&B in our gallery, [Fully Connected‚Üí](https://app.wandb.ai/gallery)\n",
        "\n",
        "#### üèôÔ∏è Community\n",
        "\n",
        "Join a community of ML practitioners in our\n",
        "[Discourse forum‚Üí](http://wandb.me/and-you)\n",
        "\n",
        "#### üìè Best Practices\n",
        "\n",
        "1. **Projects**: Log multiple runs to a project to compare them. `wandb.init(project=\"project-name\")`\n",
        "2. **Groups**: For multiple processes or cross validation folds, log each process as a run and group them together. `wandb.init(group='experiment-1')`\n",
        "3. **Tags**: Add tags to track your current baseline or production model.\n",
        "4. **Notes**: Type notes in the table to track the changes between runs.\n",
        "5. **Reports**: Take quick notes on progress to share with colleagues and make dashboards and snapshots of your ML projects.\n",
        "\n",
        "#### ü§ì Advanced Setup\n",
        "\n",
        "1. [Environment variables](https://docs.wandb.com/library/environment-variables): Set API keys in environment variables so you can run training on a managed cluster.\n",
        "2. [Offline mode](https://docs.wandb.com/library/technical-faq#can-i-run-wandb-offline): Use `dryrun` mode to train offline and sync results later.\n",
        "3. [On-prem](https://docs.wandb.com/self-hosted): Install W&B in a private cloud or air-gapped servers in your own infrastructure. We have local installations for everyone from academics to enterprise teams.\n",
        "4. [Sweeps](http://wandb.me/sweeps-colab): Set up hyperparameter search quickly with our lightweight tool for tuning.\n",
        "5. [Artifacts](http://wandb.me/artifacts-colab): Track and version models and datasets in a streamlined way that automatically picks up your pipeline steps as you train models.\n",
        "6. [Tables](http://wandb.me/dsviz-nature-colab): Log, query, and analyze tabular data. Understand your datasets, visualize model predictions, and share insights in a central dashboard."
      ]
    }
  ]
}